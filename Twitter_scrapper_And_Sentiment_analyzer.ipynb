{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BKchr0fzlSa"
      },
      "source": [
        "#Scrapping tweets from twitter\n",
        "Using snscrape for scrapping twitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8A26Yw7sOxk"
      },
      "outputs": [],
      "source": [
        "!pip install snscrape\n",
        "!pip install wordcloud\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBCefuMpr5Mh"
      },
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "\n",
        "# Created a list to append all tweet attributes(data)\n",
        "tweets = []\n",
        "\n",
        "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
        "for i,tweet_1 in enumerate(sntwitter.TwitterSearchScraper('Microsoft since:2022-11-03 until:2022-11-04').get_items()):\n",
        "    if i>100:\n",
        "        break\n",
        "    tweets.append(tweet_1.content)\n",
        "    \n",
        "# Creating a dataframe from the tweets list above \n",
        "# tweets_df = pd.DataFrame(attributes_container, columns=[\"Date Created\", \"Number of Likes\", \"Source of Tweet\", \"Tweets\"])\n",
        "tweets_df = pd.DataFrame (tweets, columns= ['Tweets'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_kHAMCIr_ez"
      },
      "outputs": [],
      "source": [
        "#function to clean the text\n",
        "import re\n",
        "import matplotlib.pyplot as pl\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "import numpy as np\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9]+','',text) #removed @ mentions\n",
        "    text = re.sub(r'#', '', text) # removed # tags\n",
        "    text = re.sub(r'RT[\\s]+','', text) # removed Retweets\n",
        "    text = re.sub(r'https?:\\/\\/\\S+','', text) # removed hyperlinks\n",
        "\n",
        "    return text\n",
        "\n",
        "tweets_df['Tweets'] = tweets_df['Tweets'].apply(clean_text)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YToHVBW0PzW0",
        "outputId": "c825c2cf-736e-4502-88b5-6fd14d79541b"
      },
      "outputs": [],
      "source": [
        "#load the model and tokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "from scipy.special import softmax\n",
        "\n",
        "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained (roberta)\n",
        "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
        "\n",
        "\n",
        "\n",
        "def getScores (text):\n",
        "  encoded_tweet = tokenizer ( text, return_tensors = 'pt')\n",
        "  output = model(**encoded_tweet)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "  return scores\n",
        "\n",
        "\n",
        "\n",
        "tweets_df['Sentiment'] = tweets_df['Tweets'].apply(getScores)\n",
        "\n",
        "neg_t = 0\n",
        "pos_t = 0\n",
        "net_t = 0\n",
        "for i in range(100):\n",
        "  temp = tweets_df['Sentiment'][i][0]\n",
        "  neg_t = neg_t + temp\n",
        "  temp = tweets_df['Sentiment'][i][1]\n",
        "  net_t = net_t + temp\n",
        "  temp = tweets_df['Sentiment'][i][2]\n",
        "  pos_t = pos_t + temp\n",
        "avg_neg = neg_t/100\n",
        "avg_net = net_t/100\n",
        "avg_pos = pos_t/100\n",
        "print('avg Positive = ', avg_pos)\n",
        "print('avg Negative = ', avg_neg)\n",
        "print('avg Neutral = ', avg_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJQS2J4WwmH-"
      },
      "outputs": [],
      "source": [
        "\n",
        "#sentiment analysis\n",
        "# for i in range(100):\n",
        "#   encoded_tweet = tokenizer ( tweets_df['Tweets'][i], return_tensors = 'pt')\n",
        "# print(encoded_tweet)\n",
        "  # output = model(**encoded_tweet)\n",
        "  # scores = output[0][0].detach().numpy()\n",
        "  # scores = softmax(scores)\n",
        "# print(scores)\n",
        "  # for i in range(len(scores)):\n",
        "  #   l = labels[i] \n",
        "  #   s = scores[i]\n",
        "\n",
        "  #   print(l,s)\n",
        "# 1 negative 2 neutral 3 positive\n",
        "# labels = ['Negative','Neutral', 'Positive']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OkHmmv3sb4G",
        "outputId": "2b4d7ced-5300-427d-f018-f001137de35f"
      },
      "outputs": [],
      "source": [
        "#using Polarity and subjectivity to analyse the sentiment\n",
        "# create a function t get subjectivity\n",
        "\n",
        "def getSubjectivity(text):\n",
        "    return [TextBlob(text).sentiment.subjectivity , TextBlob(text).sentiment.polarity]\n",
        "\n",
        "# Create two new column\n",
        "# tweets_df['subjectivity'] = tweets_df['Tweets'].apply(getSubjectivity)\n",
        "# tweets_df['polarity'] = tweets_df['Tweets'].apply(getPolarity)\n",
        "tweets_df['subjectivity']  = tweets_df['Tweets'].apply(getSubjectivity)\n",
        "\n",
        "tweets_df['subjectivity'][9][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "fnBtBDe4sfCX",
        "outputId": "5bdb853c-d4c5-42e7-f366-58a02e0566b9"
      },
      "outputs": [],
      "source": [
        "#make a wordcloud for the words apperiang in the tweets\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "allWords = ' '.join([twts for twts in tweets_df['Tweets']])\n",
        "wc = WordCloud(width = 500, height = 300,  random_state = 21, max_font_size = 110).generate(allWords)\n",
        "\n",
        "plt.imshow(wc, interpolation = \"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uo6IWafyuhVY",
        "outputId": "52fa0d00-ff31-4d5a-bdd4-875ed66acc9d"
      },
      "outputs": [],
      "source": [
        "#create a function to compute negative neural and positive analysis\n",
        "def getAnalysis (score):\n",
        "  if score<0:\n",
        "    return 'Negative'\n",
        "  elif score ==0:\n",
        "    return 'Neutral'\n",
        "  else:\n",
        "    return 'Positive'\n",
        "\n",
        "tweets_df['Analysis']= tweets_df['polarity'].apply(getAnalysis)\n",
        "\n",
        "tweets_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDN3tFLEvtqY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
